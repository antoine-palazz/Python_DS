{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7fc313-0743-4c91-81a0-17d1760f5cb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f6a79c-0288-4159-b659-967dce3927fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "!pip install --upgrade xlrd #colab bug verson xlrd\n",
    "!pip install geopandas\n",
    "!pip install pandas fiona shapely pyproj rtree\n",
    "!pip install contextily\n",
    "!pip install pygeos\n",
    "!pip install topojson\n",
    "import geopandas as gpd\n",
    "import contextily as ctx\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "!pip install imbalanced-learn\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "!pip install factor-analyzer\n",
    "from factor_analyzer import FactorAnalyzer\n",
    "import plotly.express as px\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.colors import to_rgba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845f5954-e5cc-4d83-899f-5f7964bb518e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data_dummies.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5dbd8c-f79e-4646-9505-aeda5534caf3",
   "metadata": {},
   "source": [
    "# Regression logistique de la maladie sur l'âge.\n",
    "Il semblait assez évident que l'âge jouerait un rôle déterminant pour la contraction de maladies mais il conevnait de voir \"à quel point\". \n",
    "C'est pourquoi nous avons mené une régression logistique sur la question. \n",
    "Après plusieurs tentatives, c'est avec une méthode de ré échantillonnage et de changements de poids que nous sommes parvenus au résultat le plus précis. \n",
    "En effet, les malades atteints de cancer étant en minorité dans la population, sans modification de leur poids ou échantillonnage différent, il aurait été naturel de classer tous les individus comme bien portants pour minimiser le risque d'erreur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa6e6e4-fbd2-4480-8f45-8a8c27f9a5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_regression = df[['indicatrice__Cancers', 'classe_age']].dropna()\n",
    "\n",
    "\n",
    "X = df_regression[['classe_age']]\n",
    "y = df_regression['indicatrice__Cancers']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#re echantillonnage \n",
    "rus = RandomUnderSampler(sampling_strategy=0.5, random_state=42)\n",
    "X_resampled, y_resampled = rus.fit_resample(X_train, y_train)\n",
    "smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_resampled, y_resampled)\n",
    "\n",
    "#On change les poids\n",
    "model = LogisticRegression(class_weight='balanced')\n",
    "model.fit(X_resampled, y_resampled)\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "conf_matrix = confusion_matrix(y_test, predictions)\n",
    "classification_rep = classification_report(y_test, predictions, zero_division=1)\n",
    "\n",
    "coefficients = model.coef_[0]\n",
    "intercept = model.intercept_[0]\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Confusion Matrix:\\n{conf_matrix}')\n",
    "print(f'Classification Report:\\n{classification_rep}')\n",
    "\n",
    "print(f'Coefficients: {coefficients}')\n",
    "print(f'Intercept: {intercept}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c7b1bf-3a05-42b4-ae42-9b6571c7705f",
   "metadata": {},
   "source": [
    "On remarque que pour chaque classe d'âge franchie, les chances de contracter un cancer augmentent de 0.015, ce qui est un coefficient relativement important comparé aux résultats des autres régression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188ca175-1291-489c-bc17-92266a32f729",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "X_values = np.linspace(X.min(), X.max(), 1000).reshape(-1, 1)\n",
    "probabilities = model.predict_proba(X_values)[:, 1]\n",
    "\n",
    "plt.scatter(X, y, label='Données (peu évocateur)')\n",
    "plt.plot(X_values, probabilities, color='red', label=\"Régression logistique de 'cancer' sur l'âge\")\n",
    "plt.xlabel('Âge')\n",
    "plt.ylabel(\"Probabilité d'avoir un cancer\")\n",
    "plt.title('Courbe de régression')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd97a8a-59f0-4429-a978-40984d0239c5",
   "metadata": {},
   "source": [
    "# CLUSTERING/ACP\n",
    "Le but de cette partie est d'essayer de dresser des catégories de départements similaires. On garde plusieurs variables assez différentes, que ce soit les maladies ou les données liées à la pollution pour essayer de trouver les \"tendances lourdes\" ou des mécanismes qui pourraient sous-tendre la répartition des maladies en france. \n",
    "\n",
    "On inclut autant de variables pour essayer de trouver des catégories qui soient \"vraiment\" homogènes entre elles et qui ne soient pas trop influencées par des effets de structure (par exemple, inclure la classe d'âge et la taille de la population pour ne pas avoir un biais de variable omise et que Paris, les Bouches du Rhône ou le département du Nord soit un outlier du fait du nombre de malades, ou que les départements ayant une population plus âgée ne soit pas surreprésentés à tort du fait de leur nombre de maladies qui serait plus important)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6bdc17-d116-4db1-aaa5-069e043f6dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cluster = pd.read_csv('base_modelisation.csv')\n",
    "df_cluster = df_cluster.drop(['Unnamed: 0', 'dept', \n",
    "                              'indicatrice_Hospitalisations ponctuelles (avec ou sans pathologies, traitements ou maternité)'], axis = 1)\n",
    "df_cluster = df_cluster.set_index('dep', drop = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e217e68-e0ac-4c17-806b-d02e6eba4a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#On fait l acp et on standardise nos variables\n",
    "pca = PCA(n_components=2)\n",
    "pca_result = pca.fit_transform(df_cluster)\n",
    "pca_df = pd.DataFrame(data=pca_result, columns=['PC1', 'PC2'])\n",
    "loadings = pca.components_.T * np.sqrt(pca.explained_variance_)\n",
    "loading_matrix = pd.DataFrame(loadings, columns=['PC1', 'PC2'], index=df_cluster.columns)\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "#Cercle de correlation\n",
    "circle = plt.Circle((0, 0), 1, fill=False, edgecolor='b', linestyle='dashed')\n",
    "ax.add_patch(circle)\n",
    "for i, var in enumerate(loading_matrix.index):\n",
    "    ax.arrow(0, 0, loading_matrix.loc[var, 'PC1'], loading_matrix.loc[var, 'PC2'],\n",
    "             color='r', alpha=0.7, linewidth=0.5, head_width=0.02, head_length=0.02)\n",
    "    ax.text(loading_matrix.loc[var, 'PC1'] * 1.15, loading_matrix.loc[var, 'PC2'] * 1.15, var,\n",
    "            color='b', ha='center', va='center')\n",
    "\n",
    "ax.set_xlim([-1, 1])\n",
    "ax.set_ylim([-1, 1])\n",
    "ax.set_aspect('equal', 'box')\n",
    "ax.set_title('Cercle de corrélations')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86451a82-f4f7-4524-86d0-521c0be6b051",
   "metadata": {},
   "source": [
    "On remarque que la classe d'âge se dénote quelque peu du reste des variables liées aux maladies, elle ne contribue qu'à la première composante principale. \n",
    "Par ailleurs, on remarque que beaucoup de variables sont très liées entre elles, c'est pourquoi on effectue une ACP avec la méthode de rotation 'Promax' pour que ce soit plus interprétable et essayer de distinguer s'il n'y a pas d'autres facteurs qui peuvent être également importants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eabe3c38-5a79-4e47-b4b5-3e5d36c65bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Memes operations que precedemment mais avec la methode de rotation promax\n",
    "pca = PCA(n_components=2)\n",
    "pca_result = pca.fit_transform(df_cluster)\n",
    "pca_df = pd.DataFrame(data=pca_result, columns=['PC1', 'PC2'])\n",
    "fa = FactorAnalyzer(rotation='promax', n_factors=2)\n",
    "fa.fit(df_cluster)\n",
    "rotated_loadings = fa.loadings_\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "# Cercle de correlations\n",
    "circle = plt.Circle((0, 0), 1, fill=False, edgecolor='b', linestyle='dashed')\n",
    "ax.add_patch(circle)\n",
    "for i, var in enumerate(df_cluster.columns):\n",
    "    ax.arrow(0, 0, rotated_loadings[i, 0], rotated_loadings[i, 1],\n",
    "             color='r', alpha=0.7, linewidth=0.5, head_width=0.02, head_length=0.02)\n",
    "    ax.text(rotated_loadings[i, 0] * 1.15, rotated_loadings[i, 1] * 1.15, var,\n",
    "            color='b', ha='center', va='center')\n",
    "\n",
    "ax.set_xlim([-1, 1])\n",
    "ax.set_ylim([-1, 1])\n",
    "ax.set_aspect('equal', 'box')\n",
    "ax.set_title('Cercle de corrélations en ayant appliqué la méthode de rotation Promax')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66bcaac5-8e6a-43e0-b647-e17b08819d37",
   "metadata": {},
   "source": [
    "On remarque que les variables sont un (tout) petit peu moins groupées. Mais c'est pourquoi, afin de trouver les variables les plus intéressantes, on garde celles qui contribuent le plus aux différentes composantes principales et on laisse de côté celles qui sont déjà très corrélées aux variables et qui, par ailleurs, contribuent moins aux composantes principales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e74907-e340-42f9-9d23-2cead66481ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_to_drop = ['Energie', 'Autres transports international', 'Routier',\n",
    "                'indicatrice_Traitements psychotropes (hors pathologies)',\n",
    "                'indicatrice_Maladies cardio-neurovasculaires',\n",
    "                'indicatrice_Maladies psychiatriques', 'indicatrice_Diabète','indicatrice_Séjours en hospitalisation complète pour prise en charge de la Covid-19',\n",
    "                'indicatrice_Traitements du risque vasculaire (hors pathologies)']\n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04a42ed-5d13-4404-85b1-fcdff30be293",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cluster_reduit = df_cluster.drop(list_to_drop, axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8ddba3-4ee5-4e77-87fc-a0d288cbb685",
   "metadata": {},
   "outputs": [],
   "source": [
    "#on refait exactement les memes commandes que precemment mais avec un jeu de donnees reduit pour essayer\n",
    "#d ameliorer notre modele\n",
    "pca = PCA(n_components=2)\n",
    "pca_result_bis = pca.fit_transform(df_cluster_reduit)\n",
    "pca_df_reduit = pd.DataFrame(data=pca_result_bis, columns=['PC1', 'PC2'])\n",
    "fa = FactorAnalyzer(rotation='promax', n_factors=2)\n",
    "fa.fit(df_cluster_reduit)\n",
    "rotated_loadings = fa.loadings_\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "circle = plt.Circle((0, 0), 1, fill=False, edgecolor='b', linestyle='dashed')\n",
    "ax.add_patch(circle)\n",
    "for i, var in enumerate(df_cluster_reduit.columns):\n",
    "    ax.arrow(0, 0, rotated_loadings[i, 0], rotated_loadings[i, 1],\n",
    "             color='r', alpha=0.7, linewidth=0.5, head_width=0.02, head_length=0.02)\n",
    "    ax.text(rotated_loadings[i, 0] * 1.15, rotated_loadings[i, 1] * 1.15, var,\n",
    "            color='b', ha='center', va='center')\n",
    "\n",
    "ax.set_xlim([-1, 1])\n",
    "ax.set_ylim([-1, 1])\n",
    "ax.set_aspect('equal', 'box')\n",
    "ax.set_title('Cercle de corrélation avec moins de variables, et rotation Promax')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bed01b5-2f61-48b3-9854-aa1e21b0392f",
   "metadata": {},
   "source": [
    "On remarque que mis à part le titre et une partie des variables assez liées en pollution, le cercle de corrélations est plus lisible. \n",
    "C'est pourquoi on va mener un clustering sur ces composantes principales."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90956069-49b0-4a61-af38-20bc6798cf53",
   "metadata": {},
   "source": [
    "### Clustering k-moyennes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e13324-8a97-496c-af9d-fd438d0efbaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "wcss = []\n",
    "\n",
    "for i in range(1, 11):\n",
    "    kmeans = KMeans(n_clusters=i, init='k-means++', max_iter=300, n_init=10, random_state=0)\n",
    "    kmeans.fit(pca_df_reduit)\n",
    "    wcss.append(kmeans.inertia_)\n",
    "\n",
    "#On regarde la methode du coude\n",
    "plt.plot(range(1, 11), wcss)\n",
    "plt.title('Heuristique du coude')\n",
    "plt.xlabel('Nombre de clusters')\n",
    "plt.ylabel('Somme des carrés des distances intra cluster')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7799642-99b5-4cfd-9f82-15350db12cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=5, init='k-means++', max_iter=300, n_init=10, random_state=0)\n",
    "df_cluster_reduit['Cluster'] = kmeans.fit_predict(pca_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b38cb4-647f-49c4-b7ba-cb65a11eed79",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cluster_reduit.loc[df_cluster_reduit['Cluster'] == 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c15ba5-5ec9-4824-a49a-17920cf842fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(pca_df_reduit['PC1'], pca_df_reduit['PC2'], c=df_cluster_reduit['Cluster'], cmap='viridis')\n",
    "plt.title('Clusters faits avec les composantes principales')\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04822fbd-faa4-4dc4-829e-1e8e7e0bbde3",
   "metadata": {},
   "source": [
    "Les départements : Bouches-du-Rhône, Nord, Rhône, Seine-Maritime et la Seine-et-Marne semblent se détacher pas les deux composantes principales comparé au reste des départements. Ce sont des départements très peuplés avec des niveaux de pollution élevés du fait de la densité de la population et du degré d'urbanisme dans certains cas. On peut donc commencer à déceler un lien, dans certains cas extrêmes entre la pollution et le taux de maladies. Cependant, dans la majorité des autres cas, où la pollution est bien moindre, il est plus difficile de pouvoir quantifier l'effet de la pollution sur la santé. \n",
    "\n",
    "Il semblerait qu'il faille donc une quantité de pollution très importante pour que des effets commencent à être perceptibles à l'échelle du département. Il n'y aurait pas de relation linéaire mais davantage un effet de seuil.\n",
    "\n",
    "Pour permettre de mieux voir ces résultats et de constater l'appartenance de chaque département à un certain cluster, nous faisons ce graphique 'interactif'.\n",
    "Le clustering se base toujours sur l'ACP réduite avec la rotation promax. \n",
    "On continue de garder 5 clusters car c'est le nombre de clusters que nous avions retenus pour les cartes, et par ailleurs, la méthode du coude semble indiquer que c'est un bon résultat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d0e97f-9246-45a7-9c19-47a3c19c6289",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cluster_reduit_reset = df_cluster_reduit.reset_index()\n",
    "\n",
    "#ACP\n",
    "pca = PCA(n_components=2)\n",
    "pca_result_bis = pca.fit_transform(df_cluster_reduit_reset.drop(columns=['dep']))  \n",
    "pca_df_reduit = pd.DataFrame(data=pca_result_bis, columns=['PC1', 'PC2'])\n",
    "fa = FactorAnalyzer(rotation='promax', n_factors=2)\n",
    "fa.fit(df_cluster_reduit_reset.drop(columns=['dep'])) \n",
    "rotated_loadings = fa.loadings_\n",
    "\n",
    "#Clustering\n",
    "wcss = []\n",
    "for i in range(1, 11):\n",
    "    kmeans = KMeans(n_clusters=i, init='k-means++', max_iter=300, n_init=10, random_state=0)\n",
    "    kmeans.fit(pca_df_reduit)\n",
    "    wcss.append(kmeans.inertia_)\n",
    "\n",
    "plt.plot(range(1, 11), wcss)\n",
    "plt.title('Heuristique du coude')\n",
    "plt.xlabel('Nombre de clusters')\n",
    "plt.ylabel('Somme des carrés des distances intra-clusters')\n",
    "plt.show()\n",
    "kmeans = KMeans(n_clusters=5, init='k-means++', max_iter=300, n_init=10, random_state=0)\n",
    "df_cluster_reduit_reset['Cluster'] = kmeans.fit_predict(pca_df_reduit)\n",
    "df_combined = pd.concat([df_cluster_reduit_reset[['dep', 'Cluster']], pca_df_reduit], axis=1)\n",
    "\n",
    "# On utilise plotly pour que ce soit interactif\n",
    "fig = px.scatter(df_combined, x='PC1', y='PC2', color='Cluster',\n",
    "                 title='Clusters intéractifs', labels={'Cluster': 'Cluster'},\n",
    "                 color_continuous_scale='viridis', hover_name='dep')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e8e4aa-fa0b-49c9-a9ea-3cc6834735b2",
   "metadata": {},
   "source": [
    "# ACP et Clustering sur la tranche des 30-60 ans \n",
    "Comme nous avons remarqué que l'âge avait une place prépondérante dans la détermination de la maladie, nous avons cherché sinon à éliminer l'effet de l'âge, du moins essayer de le minorer pour voir si la pollution avait en effet un impact sur la santé. \n",
    "La classe d'âge choisie est certes hétéroclite mais nous pensons que cela pourrait être plus évocateur. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b746904-0641-4a08-bf55-b621baf896c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cluster_30_60 = pd.read_csv('base_modelisation_30_60.csv')\n",
    "df_cluster_30_60 = df_cluster_30_60.drop(['Unnamed: 0', 'dept', \n",
    "                              'indicatrice_Hospitalisations ponctuelles (avec ou sans pathologies, traitements ou maternité)'], axis = 1)\n",
    "df_cluster_30_60 = df_cluster_30_60.set_index('dep', drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8bea88-032a-4397-ac6b-614b7abb946a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(df_cluster_30_60.var())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d029fa2b-07bd-46b0-88d3-13406af7c60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#il y avait une erreur dans l acp reduite a une partie de la population\n",
    "#on remarque qu'il y a des variables dont la variance est nulle\n",
    "#on peut donc les supprimer comme elle n apportent pas d information pour categoriser la population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea93a63-3000-4589-8dd3-bad2e783ece4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cluster_30_60 = df_cluster_30_60.drop(['indicatrice_Autres affections de longue durée (dont 31 et 32)',\n",
    "                               'indicatrice_Maladies respiratoires chroniques (hors mucoviscidose)'], axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190d51e7-b246-424e-a8b1-2dfb8fe7897e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#On refait une acp en standardisant les variables et appliquant la méthode de rotation promax\n",
    "pca_30_60 = PCA(n_components=2)\n",
    "pca_result_30_60 = pca_30_60.fit_transform(df_cluster_30_60)\n",
    "pca_df_30_60 = pd.DataFrame(data=pca_result_30_60, columns=['Custom_PC1', 'Custom_PC2'])\n",
    "explained_variance_ratio = pca_30_60.explained_variance_ratio_\n",
    "fa = FactorAnalyzer(rotation='promax', n_factors=2)\n",
    "fa.fit(df_cluster_30_60)\n",
    "rotated_loadings = fa.loadings_\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "circle = plt.Circle((0, 0), 1, fill=False, edgecolor='b', linestyle='dashed')\n",
    "ax.add_patch(circle)\n",
    "for i, var in enumerate(df_cluster_30_60.columns):\n",
    "    ax.arrow(0, 0, rotated_loadings[i, 0], rotated_loadings[i, 1],\n",
    "             color='r', alpha=0.7, linewidth=0.5, head_width=0.02, head_length=0.02)\n",
    "    ax.text(rotated_loadings[i, 0] * 1.15, rotated_loadings[i, 1] * 1.15, var,\n",
    "            color='b', ha='center', va='center')\n",
    "\n",
    "ax.set_xlim([-1, 1])\n",
    "ax.set_ylim([-1, 1])\n",
    "ax.set_aspect('equal', 'box')\n",
    "ax.set_title('Cercle de corrélation pour les 30-60 ans')\n",
    "\n",
    "plt.show()\n",
    "print(f\"R-squared for PC1: {explained_variance_ratio[0]:.4f}\")\n",
    "print(f\"R-squared for PC2: {explained_variance_ratio[1]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d6f7b6a-3633-4422-950b-6fd8512e125c",
   "metadata": {},
   "source": [
    "Le choix de la tranche d'âge de 30 à 60 ans vient du fait qu'avec nos données, la moyenne des patients atteints de cancer est de 64 ans.\n",
    "Par ailleurs, comme on a pu le voir à plusieurs reprises, l'âge est un facteur décisif pour la contraction du cancer. Choisir la classe d'âge de 30 à 60 ans aurait pu mettre en lumière les cas de cancer pour les individus étant exposés à la pollution et développant ainsi un cancer \"prématurément\". \n",
    "On fait peut-être face à nouveau à un problème d'échelle. \n",
    "\n",
    "L'effet de la classe d'âge est diminué par rapport au cas où on prenait la population en entier de façon assez prévisible. Mais on remarque aussi que les variables vont moins toutes dans le même sens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50096c6-f15d-4b96-b296-5218b6780d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clustering par la méthode des k-moyennes, on garde encore 5 clusters pour pouvoir faire des comparaisons,\n",
    "#la composante 1 continue de faire une grande partie de la catégorisation\n",
    "n_clusters = 5\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "df_cluster_30_60['cluster'] = kmeans.fit_predict(pca_result_30_60)\n",
    "plt.figure(figsize=(10, 8))\n",
    "scatter = plt.scatter(pca_result_30_60[:, 0], pca_result_30_60[:, 1], c=df_cluster_30_60['cluster'], cmap='viridis')\n",
    "plt.title(\"Clustering à partir de l'ACP\")\n",
    "plt.xlabel('1ère composante principale')\n",
    "plt.ylabel('2ème composante principale')\n",
    "plt.legend(*scatter.legend_elements(), title='Clusters')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74480c9d-3b4e-4993-bdc5-0e2d634098d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cluster_30_60.to_csv(\"df_cluster_30_60.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d25682-aa48-4849-a6ce-ca549439544d",
   "metadata": {},
   "source": [
    "On remarque tout de même qu'il y a un peu plus de disparités et de variations que dans le cas où on regardait la population dans son ensemble. On peut dire qu'il y a peut-être plus d'interprétations possibles dans ce cas-là qu'auparavant, et c'est ce que l'on va essayer de voir dans les régressions logistiques. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba92ef4b-41ef-4638-828a-4db2195131bb",
   "metadata": {},
   "source": [
    "# Regression logistique bis, cas multivarié avec plusieurs facteurs explicatifs, et en prenant en compte la pollution\n",
    "On procède cette fois à l'échelle individuelle pour essayer de mettre plus en avant l'effet de la pollution non pas à l'échelle agrégée mais de chaque patient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e2c9b9-16ae-4d85-8baa-8c61dbd5b05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_reg = pd.read_csv(\"data_reg.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca81b97-fab8-420d-b16e-12e9ea1b34fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_reg = data_reg.drop(['Unnamed: 0', 'ind', 'dept'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03ec1b4-cc09-4909-be74-875519b3bd99",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_reg['classe_age'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f40f427-bb48-4217-959a-282393b85e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_reg = data_reg[data_reg['classe_age'].isin([62,67,72])]\n",
    "#ligne du dessus a enlever ou modifier  si on veut etudier une population en particulier ou la population en entier, \n",
    "#pour ceux entre 60 et 75 ans, les resultas restent similaires, et donnent une place \n",
    "#relativement faible a la pollution, la seule qui ait un effet un peu moindre que les autres est\n",
    "#Industrie hors energie, le odd ratio est autour de 1.012/1.013\n",
    "#c est donc assez peu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3aebc77-f6eb-4030-b7fb-9aad1a4f4cf0",
   "metadata": {},
   "source": [
    "# Régression cancer bis\n",
    "### Sorte d'étude de cas du cancer parmi la population la plus touchée cette fois, pour essayer de mettre en évidence un possible effet de la pollution\n",
    "On sélectionne cette fois une tranche d'âge plus réduite parce que ne comportant que les gens âgés de 60 à 75 ans. On se place donc dans le cadre précis pour étudier là où il y a le plus de cancers. \n",
    "Il va sans dire que notre approche peut être problématique en cela que l'on cherche à montrer qu'il y a une corrélation mais cela nous semblait intéressant de voir comment il était possible de quantifier les effets de la pollution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6a7799-fe75-4341-b129-9b995bb4b7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_reg_cancer = data_reg.drop(['indicatrice_Maladies cardio-neurovasculaires',\n",
    "                                'indicatrice_Maladies respiratoires chroniques (hors mucoviscidose)',\n",
    "                                'classe_age'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db03122-5d4d-4832-b8f9-940ab1554673",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ACP \"classique\", en standardisant les donnees au prealable \n",
    "\n",
    "X = data_reg_cancer.drop('indicatrice_Cancers', axis=1)\n",
    "y = data_reg_cancer['indicatrice_Cancers']\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "explained_variance_ratio = pca.explained_variance_ratio_\n",
    "r_squared = sum(explained_variance_ratio)\n",
    "print(f\"R carré pour les deux principales composantes: {r_squared:.4f}\")\n",
    "coefficients = pca.components_.T * np.sqrt(pca.explained_variance_)\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_xlim(-1, 1)\n",
    "ax.set_ylim(-1, 1)\n",
    "ax.set_xlabel(\"1ère composante principale\")\n",
    "ax.set_ylabel(\"2ème composante principale\")\n",
    "ax.set_aspect('equal')\n",
    "\n",
    "ax.axhline(0, color='black', linestyle='--', linewidth=0.5)\n",
    "ax.axvline(0, color='black', linestyle='--', linewidth=0.5)\n",
    "for i, (comp, var) in enumerate(zip(coefficients, pca.explained_variance_)):\n",
    "    circle = plt.Circle((0, 0), 1, edgecolor='r', facecolor='none')\n",
    "    ax.add_patch(circle)\n",
    "    ax.arrow(0, 0, comp[0], comp[1], color='b', width=0.01, head_width=0.1)\n",
    "    ax.text(comp[0], comp[1], X.columns[i], color='b', ha='right', va='bottom')\n",
    "plt.show()\n",
    "\n",
    "#Clustering avec la methode des k-moyennes\n",
    "n_clusters = 5\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "clusters = kmeans.fit_predict(X_scaled)\n",
    "data_reg_cancer['cluster'] = clusters\n",
    "scatter = plt.scatter(X_pca[:, 0], X_pca[:, 1], c=clusters, cmap='viridis', alpha=0.5)\n",
    "plt.title(\"Clusters avec les composantes de l'ACP\")\n",
    "plt.xlabel('1ère composante principale')\n",
    "plt.ylabel('2ème composante principale')\n",
    "\n",
    "cluster_centers_pca = pca.transform(kmeans.cluster_centers_)\n",
    "\n",
    "#on rajoute ces lignes parce qu il y a eu des problemes d affichages a repetition \n",
    "#par rapport aux codes precedents donc c est le seul changement notable\n",
    "\n",
    "legend_labels = [f'Cluster {i}' for i in range(n_clusters)]\n",
    "legend_elements = [Line2D([0], [0], marker='o', color='w', markerfacecolor=scatter.cmap(i / n_clusters), markersize=10) for i in range(n_clusters)]\n",
    "\n",
    "for i, label in enumerate(legend_elements):\n",
    "    plt.annotate(legend_labels[i], cluster_centers_pca[i], textcoords=\"offset points\", xytext=(0, 5), ha='center', fontsize=8)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "data_reg_cancer = pd.get_dummies(data_reg_cancer, columns=['cluster'], prefix = 'ind_cluster', dtype='int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70171130-12f1-44b1-b277-8b65416488dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_reg_cancer.drop('indicatrice_Cancers', axis=1)\n",
    "y = data_reg_cancer['indicatrice_Cancers']\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "#on cree des populations de controles et d autres de test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "logreg_model = LogisticRegression(class_weight={0: 1, 1: 5}) #Parce qu on s intersse aux cas ou la variable \n",
    "#est egale a un et si on ne balance pas comme ca, comme les 0 sont majoritaires, la regression classera tout le monde en 0\n",
    "\n",
    "\n",
    "logreg_model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = logreg_model.predict(X_test)\n",
    "\n",
    "\n",
    "print(\"Matrice de confusion:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"\\nRésultats:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7883addc-dbed-4d50-a95e-4a5a6fb5db57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#on effectue maintenant une regression logistique en changeant les faisant du re echantillonnage\n",
    "#n ameliore pas enormement les resultats\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "logreg_model_resampled = LogisticRegression()\n",
    "logreg_model_resampled.fit(X_resampled, y_resampled)\n",
    "y_pred_resampled = logreg_model_resampled.predict(X_test)\n",
    "\n",
    "print(\"\\nMatrice de confusion avec du ré echantillonnage:\")\n",
    "print(confusion_matrix(y_test, y_pred_resampled))\n",
    "\n",
    "print(\"\\nRésultats:\")\n",
    "print(classification_report(y_test, y_pred_resampled))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd67f5e-213d-4a40-b5bf-0247c6a8a525",
   "metadata": {},
   "outputs": [],
   "source": [
    "#on regarde les coefficients des differentes variables\n",
    "#on a inclus l appartenance a certains clusters\n",
    "coefficients = logreg_model_resampled.coef_[0]\n",
    "intercept = logreg_model_resampled.intercept_[0]\n",
    "\n",
    "coefficients_df = pd.DataFrame({'Variable': X.columns, 'Coefficient': coefficients})\n",
    "\n",
    "coefficients_df['Odds Ratio'] = coefficients_df['Coefficient'].apply(lambda x: round(np.exp(x), 4))\n",
    "coefficients_df['Effet'] = coefficients_df['Odds Ratio'].apply(lambda x: f\"Augmente de {x} \" if x > 1 else f\"Baisse de {round(1/x, 4)}\")\n",
    "\n",
    "print(coefficients_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f8a171-f9d0-4be8-b704-3888299a5aad",
   "metadata": {},
   "source": [
    "Clusters 2 et 3 semblent avoir un effet sur les cas, à nouveau assez petit mais tout de même.\n",
    "Il peut y avoir une petite correlation, le cluster 3 est celui avec le plus de pollution par les deux composantes principales. \n",
    "\n",
    "Le cluster 2 quant à lui a assez peu de CO2 biomasse hors-total mais a une pollution agricole plus importante.\n",
    "Par ailleurs, le nom des clusters changeant à chaque fois que l'on fait tourner le code, il se peut qu'ils ne correspondent plus au bon numéro. \n",
    "\n",
    "Néanmoins, il apparaît que le cluster qui causerait une augmentation de .02 soit l'une des variables avec le plus grand coefficient que l'on ait pu trouver tout au long de nos analyses. \n",
    "Il semblerait donc qu'il puisse y avoir une corrélation ici plus importante qu'ailleurs mais les résultats étant tout de même assez peu évocateurs et notre connaissance des régressions logistiques étant moins développée que celle sur les régressions linéaires, nous ne voulons pas non plus considérer ce résultat comme la réponse à tous nos problèmes. \n",
    "\n",
    "De plus, nous avons fait cette régression pour montrer spéficiquement l'effet de la pollution sur la santé et nous sommes placés dans le cas le plus favorables à ce qu'il y ait des effets plus \"amplifiés\". On peut donc avancer qu'il semble avoir une corrélation mais ce n'est pas un résultat qui permettrait d'affirmer ou de donner clairement une quantification de l'effet de la pollution sur la santé."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa25963-80f4-442d-bf55-3a664c4a841a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#on cree deux nouveaux data frames pour pouvoir faire des regressions sur les variables \n",
    "#qui nous interessent\n",
    "data_reg_neuro = data_reg.drop(['indicatrice_Cancers',\n",
    "                                'indicatrice_Maladies respiratoires chroniques (hors mucoviscidose)'], axis = 1)\n",
    "\n",
    "data_reg_resp =  data_reg.drop(['indicatrice_Cancers',\n",
    "                                'indicatrice_Maladies cardio-neurovasculaires'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4737e478-1589-4a49-9d80-505a1040e041",
   "metadata": {},
   "source": [
    "### Regression maladies respiratoires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8f3304-1fad-417c-9e98-acf312220728",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Regression\n",
    "X = data_reg_resp.drop('indicatrice_Maladies respiratoires chroniques (hors mucoviscidose)', axis=1)\n",
    "y = data_reg_resp['indicatrice_Maladies respiratoires chroniques (hors mucoviscidose)']\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "logreg_model = LogisticRegression(class_weight='balanced')\n",
    "logreg_model.fit(X_train, y_train)\n",
    "y_pred = logreg_model.predict(X_test)\n",
    "\n",
    "\n",
    "print(\"Matrice de confusion:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"\\nRésultat:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "logreg_model_resampled = LogisticRegression()\n",
    "logreg_model_resampled.fit(X_resampled, y_resampled)\n",
    "y_pred_resampled = logreg_model_resampled.predict(X_test)\n",
    "\n",
    "print(\"\\nMatrice de confusion:\")\n",
    "print(confusion_matrix(y_test, y_pred_resampled))\n",
    "\n",
    "print(\"\\nResultat:\")\n",
    "print(classification_report(y_test, y_pred_resampled))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811e5e29-92a8-4181-bb25-25daeca1e87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficients = logreg_model_resampled.coef_[0]\n",
    "intercept = logreg_model_resampled.intercept_[0]\n",
    "\n",
    "\n",
    "coefficients_df = pd.DataFrame({'Variable': X.columns, 'Coefficient': coefficients})\n",
    "\n",
    "\n",
    "coefficients_df['Odds Ratio'] = coefficients_df['Coefficient'].apply(lambda x: round(np.exp(x), 4))\n",
    "coefficients_df['Effet'] = coefficients_df['Odds Ratio'].apply(lambda x: f\"Augmente de{x}\" if x > 1 else f\"Baisse de{round(1/x, 4)} \")\n",
    "\n",
    "print(coefficients_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939a5ef3-3be8-4277-86b4-cbcbdd86f824",
   "metadata": {},
   "source": [
    "### Régression maladies neurologiques et cardiaques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d25449-f4b2-4aac-ad14-5c2c6b6a8855",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_reg_neuro.drop('indicatrice_Maladies cardio-neurovasculaires', axis=1)\n",
    "y = data_reg_neuro['indicatrice_Maladies cardio-neurovasculaires']\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "logreg_model = LogisticRegression(class_weight='balanced')\n",
    "logreg_model.fit(X_train, y_train)\n",
    "y_pred = logreg_model.predict(X_test)\n",
    "\n",
    "print(\"Matrice de confusion:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"\\nRésultats:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "logreg_model_resampled = LogisticRegression()\n",
    "logreg_model_resampled.fit(X_resampled, y_resampled)\n",
    "y_pred_resampled = logreg_model_resampled.predict(X_test)\n",
    "\n",
    "print(\"\\nMatrice de confusion:\")\n",
    "print(confusion_matrix(y_test, y_pred_resampled))\n",
    "\n",
    "print(\"\\nRésultats:\")\n",
    "print(classification_report(y_test, y_pred_resampled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594a0947-2690-430c-a07a-8007e9ed1a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficients = logreg_model_resampled.coef_[0]\n",
    "intercept = logreg_model_resampled.intercept_[0]\n",
    "\n",
    "\n",
    "coefficients_df = pd.DataFrame({'Variable': X.columns, 'Coefficient': coefficients})\n",
    "\n",
    "coefficients_df['Odds Ratio'] = coefficients_df['Coefficient'].apply(lambda x: round(np.exp(x), 4))\n",
    "coefficients_df['Effet'] = coefficients_df['Odds Ratio'].apply(lambda x: f\"Augmente de {x} \" if x > 1 else f\"Baisse de {round(1/x, 4)}\")\n",
    "\n",
    "print(coefficients_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093e930b-ec2a-438e-b4f5-9a81c83c7ef7",
   "metadata": {},
   "source": [
    "On remarque dans les deux dernière régressions que l'on a faites que les résultats sont moins parlants. \n",
    "Nous n'avons certes pas choisi les âges de sorte à ce que la population soit la plus encline à être malade mais cela permet aussi de remettre en perspective le résultat que nous avons obtenu précédemment. \n",
    "Avec les données par départements, à moins de \"grossir le trait\" de façon conséquente, comme nous avons pu le faire pour le cas du cancer, il est difficile de percevoir des effets notables sur la santé de la population. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b62d9c-c1a8-479e-8d7b-e502261a5882",
   "metadata": {},
   "source": [
    "# CONCLUSION DE LA PARTIE II :\n",
    "l'âge c'est très fort\n",
    "à âge égal la pollution joue un peu \n",
    "dès qu'on s'éloigne de ca y'a trop de corrélations entres les variables\n",
    "Ducoup l'état de santé du département dépend essentiellement de l'âge puis un peu de la pollution et enfin de plusieurs petit facteurs indéterminés\n",
    "\n",
    "# CONCLUSION DE LA PARTIE II :\n",
    "l'âge c'est très fort\n",
    "à âge égal la pollution joue un peu \n",
    "dès qu'on s'éloigne de ca y'a trop de corrélations entres les variables\n",
    "Ducoup l'état de santé du département dépend essentiellement de l'âge puis un peu de la pollution et enfin de plusieurs petit facteurs indéterminés\n",
    "\n",
    "# CONCLUSION DU PROJET :\n",
    "On ne peut pas facilement déterminer l'état de santé des individus au sein d'un déparetement en se focalisant sur quelques variables pécises.\n",
    "La seule variable qui a un pouvoir prédictif satisfaisant c'est l'âge. Donc en somme ce que nous donne l'état de santé du département c'est surtout\n",
    "l'âge de la population et un petit peu son état de pollution. (excepté peut etre les cas extereme comme les dom tom mais même eux il doit y avoir\n",
    "trop de varibales cachées). \n",
    "\n",
    "La réponse à la question est donc : non , il n'est pas pertinent de considérer le département dans le cadre d'une analyse de la santé de la population, \n",
    "excepté pour se référer à l'âge de ses résidents.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf9cdb6-8e16-4c3b-aa01-012ec96cd3b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
