{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f6a79c-0288-4159-b659-967dce3927fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "!pip install --upgrade xlrd #colab bug verson xlrd\n",
    "!pip install geopandas\n",
    "!pip install pandas fiona shapely pyproj rtree\n",
    "!pip install contextily\n",
    "!pip install pygeos\n",
    "!pip install topojson\n",
    "import geopandas as gpd\n",
    "import contextily as ctx\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "!pip install imbalanced-learn\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "!pip install factor-analyzer\n",
    "from factor_analyzer import FactorAnalyzer\n",
    "import plotly.express as px\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845f5954-e5cc-4d83-899f-5f7964bb518e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data_dummies.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa6e6e4-fbd2-4480-8f45-8a8c27f9a5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_regression = df[['indicatrice__Cancers', 'classe_age']].dropna()\n",
    "\n",
    "# Extract the independent variable (X) and dependent variable (y)\n",
    "X = df_regression[['classe_age']]\n",
    "y = df_regression['indicatrice__Cancers']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Resample the training data to address class imbalance\n",
    "rus = RandomUnderSampler(sampling_strategy=0.5, random_state=42)\n",
    "X_resampled, y_resampled = rus.fit_resample(X_train, y_train)\n",
    "\n",
    "# Apply SMOTE to the resampled data\n",
    "smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_resampled, y_resampled)\n",
    "\n",
    "# Create a logistic regression model with balanced class weights\n",
    "model = LogisticRegression(class_weight='balanced')\n",
    "\n",
    "# Fit the model to the resampled training data\n",
    "model.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Make predictions on the testing data\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "conf_matrix = confusion_matrix(y_test, predictions)\n",
    "classification_rep = classification_report(y_test, predictions, zero_division=1)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Confusion Matrix:\\n{conf_matrix}')\n",
    "print(f'Classification Report:\\n{classification_rep}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188ca175-1291-489c-bc17-92266a32f729",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "X_values = np.linspace(X.min(), X.max(), 1000).reshape(-1, 1)\n",
    "probabilities = model.predict_proba(X_values)[:, 1]\n",
    "\n",
    "plt.scatter(X, y, label='Original data')\n",
    "plt.plot(X_values, probabilities, color='red', label='Logistic regression curve')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Probability of Cancer')\n",
    "plt.title('Logistic Regression of Cancer on Age')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35dffbf3-c4c4-4cb6-8f49-1f3890b4c999",
   "metadata": {},
   "outputs": [],
   "source": [
    "#regression logisitique qu'il faudra interpreter à un moment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35ee1c3-50e1-4b1c-bc68-0323afd201f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CLUSTERING/PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6bdc17-d116-4db1-aaa5-069e043f6dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cluster = pd.read_csv('base_modelisation.csv')\n",
    "df_cluster = df_cluster.drop(['Unnamed: 0', 'dept', \n",
    "                              'indicatrice_Hospitalisations ponctuelles (avec ou sans pathologies, traitements ou maternité)'], axis = 1)\n",
    "df_cluster = df_cluster.set_index('dep', drop = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e217e68-e0ac-4c17-806b-d02e6eba4a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)  # Set the number of components you want\n",
    "pca_result = pca.fit_transform(df_cluster)\n",
    "pca_df = pd.DataFrame(data=pca_result, columns=['PC1', 'PC2'])\n",
    "loadings = pca.components_.T * np.sqrt(pca.explained_variance_)\n",
    "loading_matrix = pd.DataFrame(loadings, columns=['PC1', 'PC2'], index=df_cluster.columns)\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "# Plot circle\n",
    "circle = plt.Circle((0, 0), 1, fill=False, edgecolor='b', linestyle='dashed')\n",
    "ax.add_patch(circle)\n",
    "\n",
    "# Plot arrows for each variable\n",
    "for i, var in enumerate(loading_matrix.index):\n",
    "    ax.arrow(0, 0, loading_matrix.loc[var, 'PC1'], loading_matrix.loc[var, 'PC2'],\n",
    "             color='r', alpha=0.7, linewidth=0.5, head_width=0.02, head_length=0.02)\n",
    "    ax.text(loading_matrix.loc[var, 'PC1'] * 1.15, loading_matrix.loc[var, 'PC2'] * 1.15, var,\n",
    "            color='b', ha='center', va='center')\n",
    "\n",
    "ax.set_xlim([-1, 1])\n",
    "ax.set_ylim([-1, 1])\n",
    "ax.set_aspect('equal', 'box')\n",
    "ax.set_title('Circle of Correlation')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eabe3c38-5a79-4e47-b4b5-3e5d36c65bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "pca_result = pca.fit_transform(df_cluster)\n",
    "pca_df = pd.DataFrame(data=pca_result, columns=['PC1', 'PC2'])\n",
    "\n",
    "# Promax rotation\n",
    "fa = FactorAnalyzer(rotation='promax', n_factors=2)\n",
    "fa.fit(df_cluster)\n",
    "rotated_loadings = fa.loadings_\n",
    "\n",
    "# Plot the Circle of Correlation with Promax rotation\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "# Plot circle\n",
    "circle = plt.Circle((0, 0), 1, fill=False, edgecolor='b', linestyle='dashed')\n",
    "ax.add_patch(circle)\n",
    "\n",
    "# Plot arrows for each variable after rotation\n",
    "for i, var in enumerate(df_cluster.columns):\n",
    "    ax.arrow(0, 0, rotated_loadings[i, 0], rotated_loadings[i, 1],\n",
    "             color='r', alpha=0.7, linewidth=0.5, head_width=0.02, head_length=0.02)\n",
    "    ax.text(rotated_loadings[i, 0] * 1.15, rotated_loadings[i, 1] * 1.15, var,\n",
    "            color='b', ha='center', va='center')\n",
    "\n",
    "ax.set_xlim([-1, 1])\n",
    "ax.set_ylim([-1, 1])\n",
    "ax.set_aspect('equal', 'box')\n",
    "ax.set_title('Circle of Correlation with Promax Rotation')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e74907-e340-42f9-9d23-2cead66481ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_to_drop = ['Energie', 'Autres transports international', 'Routier',\n",
    "                'indicatrice_Traitements psychotropes (hors pathologies)',\n",
    "                'indicatrice_Maladies cardio-neurovasculaires',\n",
    "                'indicatrice_Maladies psychiatriques', 'indicatrice_Diabète','indicatrice_Séjours en hospitalisation complète pour prise en charge de la Covid-19',\n",
    "                'indicatrice_Traitements du risque vasculaire (hors pathologies)']\n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04a42ed-5d13-4404-85b1-fcdff30be293",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cluster_reduit = df_cluster.drop(list_to_drop, axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8ddba3-4ee5-4e77-87fc-a0d288cbb685",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "pca_result_bis = pca.fit_transform(df_cluster_reduit)\n",
    "pca_df_reduit = pd.DataFrame(data=pca_result_bis, columns=['PC1', 'PC2'])\n",
    "\n",
    "# Promax rotation\n",
    "fa = FactorAnalyzer(rotation='promax', n_factors=2)\n",
    "fa.fit(df_cluster_reduit)\n",
    "rotated_loadings = fa.loadings_\n",
    "\n",
    "# Plot the Circle of Correlation with Promax rotation\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "# Plot circle\n",
    "circle = plt.Circle((0, 0), 1, fill=False, edgecolor='b', linestyle='dashed')\n",
    "ax.add_patch(circle)\n",
    "\n",
    "# Plot arrows for each variable after rotation\n",
    "for i, var in enumerate(df_cluster_reduit.columns):\n",
    "    ax.arrow(0, 0, rotated_loadings[i, 0], rotated_loadings[i, 1],\n",
    "             color='r', alpha=0.7, linewidth=0.5, head_width=0.02, head_length=0.02)\n",
    "    ax.text(rotated_loadings[i, 0] * 1.15, rotated_loadings[i, 1] * 1.15, var,\n",
    "            color='b', ha='center', va='center')\n",
    "\n",
    "ax.set_xlim([-1, 1])\n",
    "ax.set_ylim([-1, 1])\n",
    "ax.set_aspect('equal', 'box')\n",
    "ax.set_title('Circle of Correlation with Promax Rotation')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e13324-8a97-496c-af9d-fd438d0efbaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "wcss = []  # Within-Cluster Sum of Squares\n",
    "\n",
    "for i in range(1, 11):\n",
    "    kmeans = KMeans(n_clusters=i, init='k-means++', max_iter=300, n_init=10, random_state=0)\n",
    "    kmeans.fit(pca_df_reduit)\n",
    "    wcss.append(kmeans.inertia_)\n",
    "\n",
    "# Plot the elbow method\n",
    "plt.plot(range(1, 11), wcss)\n",
    "plt.title('Elbow Method')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('WCSS')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7799642-99b5-4cfd-9f82-15350db12cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=4, init='k-means++', max_iter=300, n_init=10, random_state=0)\n",
    "df_cluster_reduit['Cluster'] = kmeans.fit_predict(pca_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c15ba5-5ec9-4824-a49a-17920cf842fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(pca_df_reduit['PC1'], pca_df_reduit['PC2'], c=df_cluster_reduit['Cluster'], cmap='viridis')\n",
    "plt.title('PCA Clusters')\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d0e97f-9246-45a7-9c19-47a3c19c6289",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cluster_reduit_reset = df_cluster_reduit.reset_index()\n",
    "\n",
    "# Print columns of df_cluster_reduit_reset\n",
    "print(\"Columns of df_cluster_reduit_reset:\", df_cluster_reduit_reset.columns)\n",
    "\n",
    "# PCA with Promax rotation\n",
    "pca = PCA(n_components=2)\n",
    "pca_result_bis = pca.fit_transform(df_cluster_reduit_reset.drop(columns=['dep']))  # Exclude 'dep' from PCA\n",
    "pca_df_reduit = pd.DataFrame(data=pca_result_bis, columns=['PC1', 'PC2'])\n",
    "\n",
    "# Promax rotation\n",
    "fa = FactorAnalyzer(rotation='promax', n_factors=2)\n",
    "fa.fit(df_cluster_reduit_reset.drop(columns=['dep']))  # Exclude 'dep' from factor analysis\n",
    "rotated_loadings = fa.loadings_\n",
    "\n",
    "# Elbow Method for determining the optimal number of clusters\n",
    "wcss = []  # Within-Cluster Sum of Squares\n",
    "\n",
    "for i in range(1, 11):\n",
    "    kmeans = KMeans(n_clusters=i, init='k-means++', max_iter=300, n_init=10, random_state=0)\n",
    "    kmeans.fit(pca_df_reduit)\n",
    "    wcss.append(kmeans.inertia_)\n",
    "\n",
    "# Plot the elbow method\n",
    "plt.plot(range(1, 11), wcss)\n",
    "plt.title('Elbow Method')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('WCSS')\n",
    "plt.show()\n",
    "\n",
    "# K-means clustering\n",
    "kmeans = KMeans(n_clusters=4, init='k-means++', max_iter=300, n_init=10, random_state=0)\n",
    "df_cluster_reduit_reset['Cluster'] = kmeans.fit_predict(pca_df_reduit)\n",
    "\n",
    "# Combine PCA results with original DataFrame, including 'dep'\n",
    "df_combined = pd.concat([df_cluster_reduit_reset[['dep', 'Cluster']], pca_df_reduit], axis=1)\n",
    "\n",
    "# Scatter plot with cluster labels and \"dep\" values using Plotly\n",
    "fig = px.scatter(df_combined, x='PC1', y='PC2', color='Cluster',\n",
    "                 title='PCA Clusters with Labels', labels={'Cluster': 'Cluster'},\n",
    "                 color_continuous_scale='viridis', hover_name='dep')\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd882a9-1c83-439d-ada3-600f28df217e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b746904-0641-4a08-bf55-b621baf896c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cluster_30_60 = pd.read_csv('base_modelisation_30_60.csv')\n",
    "df_cluster_30_60 = df_cluster_30_60.drop(['Unnamed: 0', 'dept', \n",
    "                              'indicatrice_Hospitalisations ponctuelles (avec ou sans pathologies, traitements ou maternité)'], axis = 1)\n",
    "df_cluster_30_60 = df_cluster_30_60.set_index('dep', drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8bea88-032a-4397-ac6b-614b7abb946a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(df_cluster_30_60.var())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d029fa2b-07bd-46b0-88d3-13406af7c60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#il y avait une erreur dans l acp reduite a une partie de la population\n",
    "#on remarque qu'il y a des variables dont la variance est nulle\n",
    "#on peut donc les supprimer comme elle n apportent pas d information pour categoriser la population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea93a63-3000-4589-8dd3-bad2e783ece4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cluster_30_60 = df_cluster_30_60.drop(['indicatrice_Autres affections de longue durée (dont 31 et 32)',\n",
    "                               'indicatrice_Maladies respiratoires chroniques (hors mucoviscidose)'], axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190d51e7-b246-424e-a8b1-2dfb8fe7897e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_30_60 = PCA(n_components=2)\n",
    "pca_result_30_60 = pca_30_60.fit_transform(df_cluster_30_60)\n",
    "pca_df_30_60 = pd.DataFrame(data=pca_result_30_60, columns=['Custom_PC1', 'Custom_PC2'])  # Change variable names\n",
    "\n",
    "# Promax rotation\n",
    "fa = FactorAnalyzer(rotation='promax', n_factors=2)\n",
    "fa.fit(df_cluster_30_60)\n",
    "rotated_loadings = fa.loadings_\n",
    "\n",
    "# Plot the Circle of Correlation with Promax rotation\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "# Plot circle\n",
    "circle = plt.Circle((0, 0), 1, fill=False, edgecolor='b', linestyle='dashed')\n",
    "ax.add_patch(circle)\n",
    "\n",
    "# Plot arrows for each variable after rotation\n",
    "for i, var in enumerate(df_cluster_30_60.columns):\n",
    "    ax.arrow(0, 0, rotated_loadings[i, 0], rotated_loadings[i, 1],\n",
    "             color='r', alpha=0.7, linewidth=0.5, head_width=0.02, head_length=0.02)\n",
    "    ax.text(rotated_loadings[i, 0] * 1.15, rotated_loadings[i, 1] * 1.15, var,\n",
    "            color='b', ha='center', va='center')\n",
    "\n",
    "ax.set_xlim([-1, 1])\n",
    "ax.set_ylim([-1, 1])\n",
    "ax.set_aspect('equal', 'box')\n",
    "ax.set_title('Circle of Correlation with Promax Rotation for df_cluster_30_60')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c7aa18-c871-4d1e-9bc5-fe77d6b053a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#on remarque que l age a encore une place preponderante dans la \n",
    "#constitution des composantes principales "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba92ef4b-41ef-4638-828a-4db2195131bb",
   "metadata": {},
   "source": [
    "# Regression logistique bis, cas multivarié avec plusieurs facteurs explicatifs, et en prenant en compte la pollution\n",
    "On procède cette fois à l'échelle individuelle pour essayer de mettre plus en avant l'effet de la pollution non pas à l'échelle agrégée mais de chaque patient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e2c9b9-16ae-4d85-8baa-8c61dbd5b05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_reg = pd.read_csv(\"data_reg.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca81b97-fab8-420d-b16e-12e9ea1b34fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_reg = data_reg.drop(['Unnamed: 0', 'ind', 'dept'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfcf46c-145b-423c-a383-0d4f7a16601a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_reg.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6a7799-fe75-4341-b129-9b995bb4b7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_reg_cancer = data_reg.drop(['indicatrice_Maladies cardio-neurovasculaires',\n",
    "                                'indicatrice_Maladies respiratoires chroniques (hors mucoviscidose)'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0691f9a1-afb1-4f5b-abeb-7a08ba184de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_reg_neuro = data_reg.drop(['indicatrice_Cancers',\n",
    "                                'indicatrice_Maladies respiratoires chroniques (hors mucoviscidose)'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4ec338-1113-448d-8285-29c3d0c2a7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_reg_resp =  data_reg.drop(['indicatrice_Cancers',\n",
    "                                'indicatrice_Maladies cardio-neurovasculaires'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb561e4-6d60-4fe0-bbd2-147ab18186c9",
   "metadata": {},
   "source": [
    "#### Régression cancer bis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70171130-12f1-44b1-b277-8b65416488dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_reg_cancer.drop('indicatrice_Cancers', axis=1)\n",
    "y = data_reg_cancer['indicatrice_Cancers']\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "logreg_model = LogisticRegression(class_weight={0: 1, 1: 5.5}) #Parce qu on s intersse aux cas ou la variable \n",
    "#est egale a un et si on ne balance pas comme ca, comme les 0 sont majoritaires, la regression classera tout le monde en 0\n",
    "\n",
    "\n",
    "logreg_model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = logreg_model.predict(X_test)\n",
    "\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7883addc-dbed-4d50-a95e-4a5a6fb5db57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have a DataFrame named 'data_reg_cancer' with variables 'indicatrice_Cancers', 'feature1', 'feature2', etc.\n",
    "# Replace these column names with your actual column names.\n",
    "\n",
    "# Separate the features and target variable\n",
    "X = data_reg_cancer.drop('indicatrice_Cancers', axis=1)\n",
    "y = data_reg_cancer['indicatrice_Cancers']\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Manually set class weights\n",
    "logreg_model = LogisticRegression(class_weight={0: 1, 1: 10})\n",
    "\n",
    "# Fit the model on the training data\n",
    "logreg_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = logreg_model.predict(X_test)\n",
    "\n",
    "# Display the confusion matrix and classification report\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Apply SMOTE (Synthetic Minority Over-sampling Technique)\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Create and train the model using the resampled data\n",
    "logreg_model_resampled = LogisticRegression()\n",
    "logreg_model_resampled.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Make predictions on the test data using the resampled model\n",
    "y_pred_resampled = logreg_model_resampled.predict(X_test)\n",
    "\n",
    "# Display the confusion matrix and classification report for the resampled model\n",
    "print(\"\\nConfusion Matrix (Resampled Model):\")\n",
    "print(confusion_matrix(y_test, y_pred_resampled))\n",
    "\n",
    "print(\"\\nClassification Report (Resampled Model):\")\n",
    "print(classification_report(y_test, y_pred_resampled))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd67f5e-213d-4a40-b5bf-0247c6a8a525",
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficients = logreg_model_resampled.coef_[0]\n",
    "intercept = logreg_model_resampled.intercept_[0]\n",
    "\n",
    "# Create a DataFrame to display the coefficients and their effects\n",
    "coefficients_df = pd.DataFrame({'Variable': X.columns, 'Coefficient': coefficients})\n",
    "\n",
    "# Calculate the odds ratio and its effect\n",
    "coefficients_df['Odds Ratio'] = coefficients_df['Coefficient'].apply(lambda x: round(np.exp(x), 4))\n",
    "coefficients_df['Effect'] = coefficients_df['Odds Ratio'].apply(lambda x: f\"Increases by {x} times\" if x > 1 else f\"Decreases by {round(1/x, 4)} times\")\n",
    "\n",
    "# Display the coefficients and their effects\n",
    "print(coefficients_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4737e478-1589-4a49-9d80-505a1040e041",
   "metadata": {},
   "source": [
    "### Regression maladies respiratoires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8f3304-1fad-417c-9e98-acf312220728",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have a DataFrame named 'data_reg_cancer' with variables 'indicatrice_Cancers', 'feature1', 'feature2', etc.\n",
    "# Replace these column names with your actual column names.\n",
    "\n",
    "# Separate the features and target variable\n",
    "X = data_reg_resp.drop('indicatrice_Maladies respiratoires chroniques (hors mucoviscidose)', axis=1)\n",
    "y = data_reg_resp['indicatrice_Maladies respiratoires chroniques (hors mucoviscidose)']\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Manually set class weights\n",
    "logreg_model = LogisticRegression(class_weight={0: 1, 1: 5})\n",
    "\n",
    "# Fit the model on the training data\n",
    "logreg_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = logreg_model.predict(X_test)\n",
    "\n",
    "# Display the confusion matrix and classification report\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Apply SMOTE (Synthetic Minority Over-sampling Technique)\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Create and train the model using the resampled data\n",
    "logreg_model_resampled = LogisticRegression()\n",
    "logreg_model_resampled.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Make predictions on the test data using the resampled model\n",
    "y_pred_resampled = logreg_model_resampled.predict(X_test)\n",
    "\n",
    "# Display the confusion matrix and classification report for the resampled model\n",
    "print(\"\\nConfusion Matrix (Resampled Model):\")\n",
    "print(confusion_matrix(y_test, y_pred_resampled))\n",
    "\n",
    "print(\"\\nClassification Report (Resampled Model):\")\n",
    "print(classification_report(y_test, y_pred_resampled))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811e5e29-92a8-4181-bb25-25daeca1e87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficients = logreg_model_resampled.coef_[0]\n",
    "intercept = logreg_model_resampled.intercept_[0]\n",
    "\n",
    "# Create a DataFrame to display the coefficients and their effects\n",
    "coefficients_df = pd.DataFrame({'Variable': X.columns, 'Coefficient': coefficients})\n",
    "\n",
    "# Calculate the odds ratio and its effect\n",
    "coefficients_df['Odds Ratio'] = coefficients_df['Coefficient'].apply(lambda x: round(np.exp(x), 4))\n",
    "coefficients_df['Effect'] = coefficients_df['Odds Ratio'].apply(lambda x: f\"Increases by {x} times\" if x > 1 else f\"Decreases by {round(1/x, 4)} times\")\n",
    "\n",
    "# Display the coefficients and their effects\n",
    "print(coefficients_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939a5ef3-3be8-4277-86b4-cbcbdd86f824",
   "metadata": {},
   "source": [
    "### Régression maladies neurologiques et cardiaques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d25449-f4b2-4aac-ad14-5c2c6b6a8855",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have a DataFrame named 'data_reg_cancer' with variables 'indicatrice_Cancers', 'feature1', 'feature2', etc.\n",
    "# Replace these column names with your actual column names.\n",
    "\n",
    "# Separate the features and target variable\n",
    "X = data_reg_neuro.drop('indicatrice_Maladies cardio-neurovasculaires', axis=1)\n",
    "y = data_reg_neuro['indicatrice_Maladies cardio-neurovasculaires']\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Manually set class weights\n",
    "logreg_model = LogisticRegression(class_weight={0: 1, 1: 10})\n",
    "\n",
    "# Fit the model on the training data\n",
    "logreg_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = logreg_model.predict(X_test)\n",
    "\n",
    "# Display the confusion matrix and classification report\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Apply SMOTE (Synthetic Minority Over-sampling Technique)\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Create and train the model using the resampled data\n",
    "logreg_model_resampled = LogisticRegression()\n",
    "logreg_model_resampled.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Make predictions on the test data using the resampled model\n",
    "y_pred_resampled = logreg_model_resampled.predict(X_test)\n",
    "\n",
    "# Display the confusion matrix and classification report for the resampled model\n",
    "print(\"\\nConfusion Matrix (Resampled Model):\")\n",
    "print(confusion_matrix(y_test, y_pred_resampled))\n",
    "\n",
    "print(\"\\nClassification Report (Resampled Model):\")\n",
    "print(classification_report(y_test, y_pred_resampled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594a0947-2690-430c-a07a-8007e9ed1a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficients = logreg_model_resampled.coef_[0]\n",
    "intercept = logreg_model_resampled.intercept_[0]\n",
    "\n",
    "# Create a DataFrame to display the coefficients and their effects\n",
    "coefficients_df = pd.DataFrame({'Variable': X.columns, 'Coefficient': coefficients})\n",
    "\n",
    "# Calculate the odds ratio and its effect\n",
    "coefficients_df['Odds Ratio'] = coefficients_df['Coefficient'].apply(lambda x: round(np.exp(x), 4))\n",
    "coefficients_df['Effect'] = coefficients_df['Odds Ratio'].apply(lambda x: f\"Increases by {x} times\" if x > 1 else f\"Decreases by {round(1/x, 4)} times\")\n",
    "\n",
    "# Display the coefficients and their effects\n",
    "print(coefficients_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd45c4c9-c5ab-4791-bb55-95d248f4916c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
